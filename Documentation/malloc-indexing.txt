Currently the preload case looks like this

      /-- client exe or .so--\/-------------------liballocs_preload.so--------------------------------\/----libc.so---
bound by:     ld +xwrap      ld.so           ld           .----------------------------ld           dlsym
      +--------+    +--------+    +--------+    +--------+  ld+--------+  ld+--------+ `-->+--------+    +--------+
      |malloc()|--->| caller |--->|        |--->|        |--->| index  |--->|bitmap/ |     |        |--->| malloc |
      |...     |<---| stubs  |<---|        |<---|        |<---| events |<---|arena/..|     |        |<---|        |
      +--------+    +--------+    +--------+    +--------+<-. +--------+    +--------+  .--+--------+    +--------+
     client code   allocstubs.i   user2hook.c   hook2event.c '-------------------------'  terminal-        actual
                                 (entry point)                 (indexing)  (core/utility) indirect-dlsym.c malloc
source:             stubgen.h    libmallochooks libmallochooks stubgen.h     liballocs    libmallochooks
                                 in liballocs   in liballocs  +generic.._index.h          in liballocs
which API?                      |             |              |                          |
                            user|user     hook|hook     event|event                     |hook


The in-exe case is a bit dfferent. When building an output object that
defines 'malloc', allocstubs.i also includes a bunch of stuff generated
from libmallochooks. In-executable malloc calls can get directed to our
event hooks (pre_alloc, post_nonnull_nonzero_realloc) et al, which
all gets linked in non-sharedly and calls out cross-DSO to liballocs.

                                                                       liballocs_preload.so
      /-------------------------exe----------------------------------------\/--------\/------------exe-----------\
bound by:     ld +xwrap  #define __real_*       as (* 4)  .---------------------------.as          dlsym(* 2)
      +--------+    +--------+    +--------+    +--------+  as+--------+ld.so--------+ `->+--------+    +--------+
      |malloc()|--->| caller |--->|        |--->|        |--->| index  |--->|bitmap/ |    |        |--->| malloc |
      |...     |<---| stubs  |<---|        |<---|        |<---| events |<---|arena/..|    |        |<---|        |
      +--------+    +--------+    +--------+    +--------+<-. +--------+    +--------+ .--+--------+    +--------+
     client code   allocstubs.i   user2hook.c   hook2event.c '------------------------'terminal-indirect- actual
                               in allocstubs.i in allocstubs.i (indexing) (core/utility) in allocstubs.i  malloc
                   (__wrap_*) (__wrap___real_*)                stubgen.h    liballocs
                    stubgen.h   libmallochooks libmallochooks +generic..._index.h        libmallochooks
                     (* 1)         in exe         in exe       in exe                       in exe
which API?                      |             |             |                           |
                            user|user     hook|hook    event|                           |hook
                                         (* 1)

The executable is linked with -lallocs and with xwrapping malloc (and
other allocation functions likewise).

For this allocscompilerwrapper.py does a two-stage link (to relocatable; to
final): it uses the first-stage output to detect which allocation functions
are present, the second to generate a bunch of extra code that instantiates
bits of libmallochooks and also the generic_malloc_index.h inline functions.
These call out to the bigalloc and arena functions in liballocs.

(* 1) these '__wrap_malloc' and friends are aliased to just 'malloc' and
friends

PROBLEM 1 with the new approach to the exe case: it used to be that the
__wrap___real_* entry points got defsym'd to the unqualified symbol name,
thereby taking over for dynamic linking purposes. NOw, with xwrap, it's
the caller-side wrapper that gets the global symbol name. So we sometimes
have an extra layer of caller-side hooking going on, if the caller is in
another DSO that gets linked the more common way, with just caller-side stubs
calling out to 'malloc' etc.

PROBLEM 2 with the new approach to the exe case: since more stuff gets
linked into the exe, the 'no-load' case has got slower. I'm not even
sure it works at all... untested at the moment.

(* 2) we use the indirect dlsym termination but we could use the
direct termination. Should just need to #undef __real_malloc FIXME: look into this.

(* 3): the hook API is narrower than the user API. Why? It saves
per-instrumentation effort in cases where userapi call A can be
expressed in terms of call B. In theory it might slow things down, if a
given malloc implementation has optimised call A but not call B. E.g. a
calloc emulated as {malloc;bzero} might miss a zero-page copy-on-write
optimisation. Arguably bzero could be optimised equivalently, e.g. via a
page-swapping facility, but the necessary facilities might not exist.
Ideally we would give instrumentation clients the choice here:
instrument calloc or not. Can use the presence of macro
__next_hook_calloc to test for this? Ideally just the absence of a
hook_calloc would be enough to tell us to emulate calloc. 'Us' is the
user2hook wrappers, *not* the user instrumentation.

(* 4) "bound by as" means this is all going on in a single compilation
unit, so the inter-section references are not subject to link-time
wrapping -- unlike the ld +xwrap cases.

FIXME: there was a nasty non-orthogonality in the 'deep' indexing
instrumentation. IIRC, too much happens in the stubgen.h-generated stubs,
and our env vars are non-orthogonal. Fix this here?

FIXME: then eliminate the whole two-stage link machinery.

FIXME: then eliminate the compiler wrapper. With all that wrap/globalize/unbind stuff
gone away, and the two-stage link, it should be toolsub'able quite easily.


