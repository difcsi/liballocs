#!/bin/bash

# HACK: know where to find toolsub
TOOLSUB="${TOOLSUB:-"$(dirname "$(readlink -f "${BASH_SOURCE[0]}")")"/../contrib/toolsub}" #"
# HACK: know where to find liballocstool
LIBALLOCSTOOL="${LIBALLOCSTOOL:-"$(dirname "$(readlink -f "${BASH_SOURCE[0]}")")"/../contrib/liballocstool}" #"

# protect our output from expansion in the client shell
# FIXME: this is very rough and ready
quote_metachars () {
    sed 's/\([() ;]\)/\\\1/g'
}

case "$0" in
    (*cflags|*cppflags|*cxxflags)
        /bin/echo -no-integrated-cpp -wrapper $(readlink -f "$(dirname "$0")")/allocs-wrapper
        exit 0
    ;;
    (*ldflags)
        # for env vars like LIBALLOCS_ALLOC_FNS, we do some light rewriting
        # and pass them as arguments to the linker plugin
        # GAH, commas interact with "-Wl," so we have to use ';'
        rewrite_liballocs_var () {
            varname="$1"
            written_one=0
            for v in ${!varname}; do
                IFS=$'\t' read ident args after <<<"$( echo "$v" | tr '()' '\t' )"
                # our format is "<ident>(<argchar> [, <argchar> ]..),[retchar]"
                # except with semicolons not commas
                if [[ $written_one -eq 1 ]]; then
                    printf " "
                fi
                printf "${ident};($(echo "$args" | sed 's/./&;/g' | sed 's/;$//'))$(echo "$after" | sed 's/->//' | sed -E 's/.+/;&/')"
                written_one=1
            done
        }
        extra_ld_args="-Wl,-plugin=$(readlink -f "$(dirname "$0")")/gold-plugin.so"
        for v in LIBALLOCS_ALLOC_FNS LIBALLOCS_FREE_FNS LIBALLOCS_ALLOCSZ_FNS \
          LIBALLOCS_SUBALLOC_FNS LIBALLOCS_SUBFREE_FNS LIBALLOCS_ALLOCSITE_OVERRIDE; do
            extra_ld_args="${extra_ld_args:+${extra_ld_args} }-Wl,-plugin-opt=`rewrite_liballocs_var $v | quote_metachars`"
        done
        printf "%s\n" "$extra_ld_args"
        exit 0
    ;;
    (*) # silently continue, i.e. actually act as the wrapper command
    ;;
esac

# source the wrapper funcs
. "${WRAPPER_FUNCS:-${TOOLSUB}/wrapper/lib/wrapper-funcs.sh}"

my_cc () {
    # Run the compiler. We force debugging information to be generated.
    # But how do we remove it?
    # FIXME: we should not force the generation if we will later run the
    # assembler and -Wa,-g or -Wa,--gen-debug is given, since those are
    # incompatible with the cc1-embedded.
    # FIXME: this -fno-eliminate...* is gcc-specific (just ditch it?)
    forcing=0
    seen_outfile=""  # FIXME: I think we can get this from stuff already parsed
    for arg in "$@"; do case "$arg" in
        (-g*)
            forcing=1
        ;;
        (*) true ;;
    esac; done
    echo "CC_DRIVER is $CC_DRIVER" 1>&2
    echo $CC_DRIVER "$@" -g3 -ggdb -fno-eliminate-unused-debug-types 1>&2
    $CC_DRIVER "$@" -g3 -ggdb -fno-eliminate-unused-debug-types 1>&2
    status=$?
    # FIXME: if we forced the generation of debug info, append a .note section
    # to the output file (or if it's '-', write to stdout)
    if ! [[ $status -eq 0 ]]; then return $status; else true; fi
}
export CC=my_cc

# we wrap 'as' so that if it's a C source file -- check from .debug_info? --
# the resulting object gets objcopy_and_redefine_c_names'd

asm_infile_is_from_c_source () {
    local f="$1"
    # look for a .file string ending .c or .i ...
    grep -q "^[[:blank:]]*\.file[[:blank:]]*\"[^\"]*\.[ci]\"" "$f" || \
        grep -q "^[[:blank:]]*\.ident[[:blank:]]*\"[^\"]*[cC][cC]\([^a-zA-Z]\|\$\)" "$f"
    # ... or (bit of a HACK) a .ident string that has 'cc' at the end of a word
}

. "$(dirname "$(readlink -f "${BASH_SOURCE[0]}")")"/lang/c/bin/link-used-types
my_as () {
    echo "as_infiles is ${as_infiles[@]}" 1>&2
    # run the assembler
    # FIXME: if no -g or --gen-debug option is given, append our '.note.stripme-g' asm file.
    # FIXME: this may differ for compiler- versus assembler-generated DWARF.
    # INTERESTINGLY, when -g is given to the compiler driver, '-g' is NOT given
    # to the assembler. Rather, the assembler heeds the embedded .file and .line
    # information that came from the compiler.
    # If -g is given to the assembler, presumably it generates .debug_line information
    # referring to the *assembly* source file. Let's try this!
    # Indeed this is correct. It generates a .debug_info too (and _abbrev and _aranges and _str,
    # but no _loc of course).
    # So in total we could generate up to three .debug_line sections!
    # One for .c, one for .i and one for .s. To get the .i one we just strip out
    # the #-directives and use what comes out of the compiler (run an additional time).
    as -g "$@"
    status=$?
    # FIXME: perhaps this rewrite should be done after cc1, not after the assembly,
    # to avoid the hacky test for C-derived assembly.
    #
    # FIXME: can we eliminate the typename fixup pass?
    # Is there a way we can use funky introspection, maybe _Generic, to directly
    # generate the correct typenames? Problem is whether this can work even with
    # old C standards that we want to support... ACTUALLY it seems to work!
    # The more annoying problem is that we need to include stdint.h which may
    # pollute the namespace.
    #
    # Even if that is not workable, maybe there is a way to do it with funky inline asm?
    # The compiler does know the size of stuff, so if we can magic up an lvalue
    # even just by a conditional expression (sizeof (int) == 4 ? &__uniqtype ... )
    # then we are good. Exactly what is it that we don't know at compile time?
    # If we can enumerate all the possible sizes of stuff, extern-declare uniqtypes
    # for them all, then only use the ones that actually apply, we will be sorted.
    # Need to ensure dollars-in-identifiers.
    # ARGH. The main problem is that we need to be able to build compound type names
    # like __uniqtype____FUN_FROM_int$$64__FUN_TO_int$$32.
    # Still maybe we can predefine BASETYPESTR_INT "int$$32". Oh, but defines don't
    # help us.
    #
    # PERHAPS a better way to do it is as follows. Do a pre-pass over the preprocessor
    # output to infer the size of base types from stuff like __SIZEOF_LONG__.
    # Then ... WHAT? A second run through the preprocessor is not out of the question,
    # but 
    # Or maybe we can run the preprocessor -dM and then scrape the #define
    # lines that we see? Can CIL grok this, or can we make it do so?
    # I think doing so is the best bet, and would allow CIL to avoid Machdep
    # except as a fallback.
    #
    # We still have to turn codeless into codeful uniqtypes. Why do we treat base
    # types specially? Can we just scrap this entirely? If we have a function from
    # struct S to struct T, we generate a uniqtype name that does not account for the
    # difference.
    #
    # YES, try this. The only transformation we should need is codeless->codeful,
    # which is not C-specific.
    # HMM. Is this messing with our canonicalisation logic?
    # We tend to treat all base type names as if they were a typedef
    # of a 'true' unambiguous name [that uses '$']. And then we always write compound names
    # in terms of the '$-containing non-typedefs. Will things break if we no longer have
    # this canonicalisation in place? My 'struct' argument above suggests not.
    # But hmm. So could we have distinct-identity uniqtypes for the same
    # base type? Not from C code, because we normalise by name. We only split
    # if the code is different. But with another lang where 32-bit signed
    # integers  are called something else, what would happen? AH, no problem.
    # Hmm, but on the generation side we need to be careful. And again the
    # compound uniqtypes are likely to be the problem... real issue is when
    # distinct symnames imply distinct identities. Our treatment of typedefs
    # is already not perfect (see GitHub).
    if ! [[ $status -eq 0 ]]; then return $status; else
        for infile in "${as_infiles[@]}"; do
            if asm_infile_is_from_c_source "${infile}" ; then
                echo "Rewriting uniqtype symnames in C-derived file $as_outfile" 1>&2
                objcopy_and_redefine_c_names "$as_outfile"
                # This .o-rewriting using the DWARF is a hack we would like to avoid.
                # Why? 
                # 1. It's papering over a problem with CIL that it doesn't reliably know
                # the actual sizes of base types.
                # 2. It's applying C-specific knowledge to .o files, requiring the nasty
                # 'grepping the assembly for something that looks like a C compiler' hack.
                # 3. It requires the gross 'until a fixed point' sed hack, i.e re-running
                # the same substitution a bounded number of times in the hope that it will
                # catch all uses of a substitutable base type name.
                #
                # Can we instead either:
                # 1. make it possible for CIL to generate the right symbol names first time? or
                # 2. do .s-rewriting in cc1, using the cpp input?
                #
                # We can do (1) by feeding CIL something preprocessed with -Wp,-dMD,
                # and teaching it to process the #-defines to scrape the machine information.
                # It should already do this; Machdep is broken. PROBLEM: does MSVC support this?
                # We will leave Machdep as a fallback.
                #
                # We can do (2) if we also use -Wp,-dMD do the same scraping here,
                # and then rewrite the assembly using the same sort of sedding. This doesn't
                # address problem 3 above and is still pretty gross.
                #
                # So let's try to make CIL generate the right symbol names first time.
                # What is 'right'? Do we want to eliminate the use of non-canonical base
                # type names altogether, say? This seems foolish because the knowledge
                # that a given alias was used seems worth hanging on to.
                # Similarly, even for the exponential blow-up case, actually generating
                # the subset of aliases that has been used in the program 
                # seems worth doing. I think 'usedtypes' needs to grok this.
                #
                # And if 'usedtypes' can grok this, why do we need the rewrite hack at all?
                # Maybe it all just needs to go in 'usedtypes' and that's that?
                # In other words, for any alias used in the file, as evidenced by an UND,
                # generate *both* that alias and the 'proper' canonical form?
                #
                # Possibly issue: what about section group discarding? If one section
                # group contains an alias and the other one doesn't, can we be sure
                # we will discard the one lacking the alias? What about if they each
                # contain a disjoint set of aliases? How can we merge them? This seems tricky.
                # It's related to the already-messed-up semantics of symbol aliases.
                # See GitHub issue #18 (https://github.com/stephenrkell/liballocs/issues/18).
                # That is a dynamic-link-time problem where aliases are bound too early,
                # so might get bound to a 'losing'(-at-uniquing-time) instance of the definition.
                # It seems this is the batch-link-time analogue of the same problem.
                # Perhaps we need to do something radical like:
                # - defer all generation of aliases until run time
                # - somehow remember which alias was requested at each reference site, e.g. as a NOTE
                # - define aliases as ABS symbols in a dlbind library, consuming the NOTES
                # - reroute the references? What would this mean? Basically nothing.
                # The NOTE section we need would I guess be "one per aliased canonical uniqtype"
                # and its contents would just list the aliases for that canonical type.
                # We could then even create the aliases at final link time, in our plugin,
                # but would need a separate (dlbind) mechanism to override the 'losing' aliases
                # that might remain visible. At each load-lib or dlopen we would have to
                # check whether the loaded lib has "would-remain-exposed" aliases of an overridden
                # symbol, and arrange to override those.
                # Are these two mechanisms both necessary?
                # (and should 'usedtypes' be a ld plugin for a relocatable link? NO, we
                # already defer 'usedtypes' until final link time).
                # There is a take-home here about ELF link-time aliasing/uniquing mechanisms
                # in general not being sufficient.
                #
                # I can't see how we could get away without the NOTE mechanism.
                # We could skip generating final-link symbols from them, and
                # simply link the notes together and handle them at run time.
                # However, we would have to resolve references to non-canonicals
                # to their canonicals. In fact I think we currently do the right thing
                # here because now that we run 'usedtypes' only at final link time,
                # we happen to union all the aliases together before we generate uniqtypes.
                # This might mean that section groups are unnecessary, even.
                # AHA. That means we don't need the NOTE mechanism, except to solve the
                # specific base-type-alias problem that we're worried about.
                # OK, small tweak: we pipe into 'usedtypes' all the UND symbols
                # beginning __uniqtype_  that there are in the link. Then, it needs
                # to generate the right aliases for these.
                #
                # This is interesting because it shows that a C++-style 'local' approach
                # to COMDAT-like stuff isn't always possible. Here we are using 'usedtypes'
                # in effect to get a bespoke merging semantics, where aliases are unioned
                # and where we use the set of extant UND references to limit how many
                # aliases we need to generate (i.e. avoiding the exponential blow-up).
                #
                # How can we do the analogous dynamic-linking thing? We need to vet
                # libraries as they're loaded, even via DT_NEEDED, which gets tricky.
                # Could make ourselves an audit client? Audit libraries get loaded
                # separately and can't easily interreference. So where does an audit
                # lib's fprintf come from? Seems to be in the ld.so, but the
                # ld.so does not contain an fprintf. Maybe its PLT does get wired up
                # to stuff in the libc?
                # The fprintf function address seems to be a register-saving trampoline.
                # Hmm, it does indeed manage to call into libc by some path.
                # Let's look at glibc's code for loading the LD_AUDIT and relocating it.
                # In rtld.c:998 it has load_audit_module   which uses dlmopen_doit,
                # i.e. it uses namespacing.
                #
                #  struct dlmopen_args *args = (struct dlmopen_args *) a;
                #  args->map = _dl_open (args->fname,
                #            (RTLD_LAZY | __RTLD_DLOPEN | __RTLD_AUDIT
                #             | __RTLD_SECURE),
                #            dl_main, LM_ID_NEWLM, _dl_argc, _dl_argv,
                #            __environ);
                #                                            ^--I think __RTLD_AUDIT just means "yes, do audit this"

                #
                # AND the last thing it does is
                #
                #  /* Mark the DSO as being used for auditing.  */
                #  dlmargs.map->l_auditing = 1;
                #
                # And in dl-open.c we have /* Do not call the functions for any auditing object.  */
                #
                # So I think it just loads it in a fresh namespace (but can still resolve libc?
                # how many copies of libc do we have? Just one. What are the semantics of
                # namespacing? MAybe already-loaded NEEDED objects from the default namespace
                # can still be used? Why is libc already loaded?
                
                # We only know about the base types' definitions if -dMD was passed.
                # HMM. A clever ruse suggests itself.
                # Is there a bunch of stuff we can output
                # inside a toplevel __asm__("..."); construct
                # that uses these? It would need to be subject to
                # preprocessing, meaning we would need to insert it
                # right at the beginning, before we run cpp.
                # Basically it would be a set of weak aliases.
                # GAH. No. This won't work.
                # Again it's the compound typenames that are the problem.
                # Any __uniqtype_* symbol that comes out of the CIL pass
                # will need rewriting. Unless CIL can generate the right
                # typenames in the first place. 
                # The deeper problem is that aliases don't scale to compound types.
                # So we need compound types' names to use canonicals.
                # Does this call into question the sanity of offering aliases for
                # simple typedefs too? Is this inherently a partial feature?
                # I think it is, yes. It might still be worth having. Or not!
                # The basic idea of issue #52 was that in 'struct stat', say,
                # it's useful to know that a given member is of type 'mode_t'
                # not just an int$16. It doesn't follow that all possible synonyms of
                # int$16 need to be materialised; the struct uses only a single
                # one of them, because it is defined in a single place.
                # The problem is types that can just be used without being
                # defined, like those using array-of or function-from or pointer-to. Each
                # use of these might use a different synonym, but still be
                # generating 'the same' array or function type.
                # Array types are OK; we can materialise those on demand.
                # Function types are a problem because the number of synonyms is
                # exponential in the number of arguments.
                # But we clearly don't need to output all the synonyms.
                break  # only do this once, if *any* infile is from C (bit of a HACK)
            fi
        done
    fi
}
export AS=my_as

# XXX: move the -ldflags down here?
#
# When wrapping compilation jobs, we have to run additional tools before
# and after the actual compiler. So, some kind of wrapper script is
# unavoidable. Our "-cflags" tool inserts the wrapper, and the wrapper
# shell functions actually run the extra stuff, e.g. the cilpp passes.
#
# With link-only jobs, it's a bit different. We can do all the work we
# need with some extra flags to the linker, to add our plugin (and turn
# on --emit-relocs). So we could just define our "-ldflags" tool to
# emit those options, and forget about '-wrapper'.
#
# Having the flags available separately is useful for hand-crafted ld jobs
# that don't run via a compiler driver. However, it's less uniform.
# Also, what if a job is doing both compilation and linking?
# We might expect the caller to insert the output of *both* `-cflags`
# and `-ldflags`. But that feels noisy.
#
# We could define a collect2 wrapper, and then have our "-ldflags" emit
# exactly the same thing as "-cflags": just the options that interpose
# the wrapper script.
#
# Probably we want both: a standalone way to get the linker flags, and
# a path that goes through this wrapper.

# Problem about state: since the wrapper gets invoked separately for
# each tool the compiler driver wants to run, there is no easy way to
# maintain state. This matters when we mess with options to one command
# but want to fix things up later. E.g. we have to insert --emit-relocs
# if absent, but later strip out the relocs if the caller didn't want
# them. Similarly with -g: we may want to strip out the debug info but
# only later.
#
# This recalls the "-flags or wrapper" issue commented above: we can add
# -g either in -cflags or in the cc1 wrapper. It's better to do it
# in the cc1 wrapper because it can test whether -g was already present.
# We probably have to do something like add a .note section to the .s
# if stripping is needed later. This basically means 'these .debug_*
# sections are not really here and won't survive the link'.

# set ourselves as the wrapper... remind me how we do this?
WRAPPER="$0"

# HACK that really needs to go away...
export CC_WRAPPER_SOURCE_TO_RUN=1
# delegate to the generic wrapper -- we've set WRAPPER so it won't re-source the funcs
. ${TOOLSUB}/wrapper/bin/wrapper
